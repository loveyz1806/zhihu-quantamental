# 关于Alternative Data的一些想法（1）

从Facebook到京东，这两天不断听到关于数据滥用的新闻，Alternative Datasets的第一次大型出场展露出了无比负面的形象。这些数据集的存在和被使用已经不是新闻，虽然关于用户隐私权的问题一直没有定论，但这些第三方数据供应商确实从合法的渠道得到了用户的信息，并且将这些数据**匿名化处理**然后产品化出来卖。比如在https://alternativedata.org/alternative-data-provider-database/上贴出来的200多个供应商，基本上已经包含了你日常大部分有商业价值的行为（如果知乎上有AD.org的朋友请给我打钱）。对于商家来说这些信息是提高业务质量的数据支持，对于市场交易来说这些信息就是**全新的alpha来源**。

本文暂时不讨论这些数据可能的道德或者隐私问题，基于其合法的共识，只单纯从一个投资者的角度去认识一下这些数据集，对数据性质、可能的使用方式、风险以及发展方向做一个简单的回顾。估计一次写不完，从回顾数据集开始，权当整理工作笔记。

### 几类常见的Alternative Dataset

单论美股市场，我目前接触过的数据包括

1. **信用卡/借记卡消费数据**。这一类数据已经被大范围使用，据说已经接近“大家都在看这个数据我不买不行”的地步。通常数据的来源有两种
   - card processor授权，用爬虫和NLP爬匿名后的用户信用卡对账单。这种方式获取数据的准确度很大程度上依赖于数据供应商对信用卡店家标记的准确性，要从简短的交易附注中标记交易的店家、支付方式（比如是实体店还是网购），一旦附注的结构甚至用词发生一些变化，那么数据集则会面临失去某个公司某个支付方式整块数据的风险；比如三月份时有一家department store做了信用卡交易附注的微调，在词组中去掉了数据集原本关注的关键字，导致其网售渠道的所有交易都没有被捕捉。
   - 更直接的来源，直接从processor和银行拿交易数据。由于是银行直接给，所以省去了从交易附注抠字做tagging的一步，因此数据更准确；然而却是数据也会更贵因为成本会更高。
2. **电子邮件收据**。举个例子：在亚马逊买了一件东西，然后亚马逊会给用户发送一封订单确认邮件，这封邮件的收据信息就会被数据供应商获得；他们同时获取的还有物流信息，精细化甚至到物流的几个主要节点（订单确认、发货、配送、确认收货），由此不仅对ecommerce的销售数据有掌握，同时对其物流渠道的质量也有了解。然而这一块数据应用量还不算大，一方面由于销售方式，传统零售商的线上销售比例还占不到足够影响全局的比例，另一方面由于数据采集质量的问题，实际可用有价值的数据太少，从数据回测结果看辣鸡太多。。。
3. **地理位置数据（geo-location）**。大概是最fancy的数据之一，宣传时糅杂了各种computer vision的技术名词，同时又隐约给人一种“big brother is watching"的紧张感（其实从数据内容和质量来看暂时他们还什么都看不见。。。）数据大概分为两类
   - 卫星数据：通常号称有40颗左右卫星覆盖全球，数据内容包括停车场数车、炼油厂油罐阴影等，然而又因为技术原因只能覆盖比如从早上十点到下午两点的数据（基本上也就只能看见不上班的了），数据历史覆盖极短，数据质量受天气影响波动也大。
   - 手机定位数据：GPS ping，后台服务刷新，数据更新频率很高大概15分钟到半小时就会刷新，单就美国而言有近千万POI，细思极恐。。。不过绑定的都是设备ID，按合规数据供应商应该拿不到个人的信息。相较于卫星数据，定位数据的准确度要高很多；尤其针对大型商场（多商家拥挤在同一小块区域）可以做更准确的定位和区分，而卫星数据没法区分停的车是来吃饭还是买东西的因而通常都会放弃这块。目前主要技术难点在去重，似乎device double counting的问题还比较严重。
4. **网页爬虫和点击流（click stream）数据**。这两种数据其实还不太一样，但通常都针对PC端且目标监测是网站流量和转化率，所以放在一起讨论。
   - 爬虫数据：爬某些URL的访问量（这个机制其实我至今还不太能理解），爬商家网上的SKU，爬网页上显示的KPI相关数据（当前活跃人数、同时在线人数、过去30天销量、目前库存等等）；对于业务重点在线上端的公司（OTA，car rental，online grocer）来说，这类数据就比其他数据要更有价值一些。然而爬虫风险也极高，技术上要应对各种反爬机制（代理池成本、时间成本），质量上还要担心公司会不会在网上放出虚假信息（对于一些不是必须放的信息公司很可能没有动机放真实数据），一旦虚假信息的事情发生，那么爬虫数据供应商的业务模式都将”面临崩溃“。
   - click stream：简而言之就是监测你在点击了x页面之后点击的下一个页面是什么，然后通过一整条点击的长链近乎还原出你在该网站上的浏览过程。优点是对网站的流量有更精细的了解，包括各页面的bouncing rate和transition matrix、不同环节上的转化漏斗、各个营销渠道的有效性，同时基于用户信息可以深入到不同的cohort、segment、geo-location去看行为上有什么差异；缺点是数据量大了以后噪音也非常大，而且最后的数据和web traffic关联比较好但由于conversion rate估计的误差导致和财报KPI的相关性还不够（web traffic -> conversion rate -> average ticket，层数太多误差累
5. **App使用数据**。类似点击流，只不过在移动端，URL endpoint以及记录cookie的方式不大适用。数据直接从Google Analytics和Adobe Analytics购买，依赖于商家必须有用这些analytics提前在App里埋tracking points否则没法追踪，但如果埋过点那么数据还是比较准确的。类似上一条，主要关注的也是流量数据，对于主营移动端的产品来说对DAU/MAU的追踪也更加准确。Points of interest规模在几亿左右，风险同时包括了噪声大、历史短和设备重复计数
6. 其他数据
   - data broker：大概算是做各种数据集集成的，什么都插一脚，数据来源大多是其他数据供应商加上一些in-house datasets
   - consensus datasets：更针对二级市场投资，通常是以上数据集需要去关联的KPI的市场一致预期数据；传统来源包括Bloomberg的卖方统计，但由于样本比较少且有sell-side bias，有时会需要听到更多的声音来对市场预期有更准确的把握
   - 具体行业相关的数据，比如餐饮业traffic数据、物流港口吞吐数据、航空航线和occupancy rate数据、OTA预订和occupancy rate数据等等，大概是只有想不到没有买不到。。。


以上只是我目前见过和接触过的数据集类型，如果有人对此了解更多也希望能再多听取一些观点和见解。客观来看目前美国在大数据挖掘和合法产品化的道路上做得比国内要快且好很多，不过趋势都已经形成，模式成熟化只是时间问题，希望能早日看到国内有更多类似的产品。
